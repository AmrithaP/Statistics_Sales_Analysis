library(tidyverse)
library(ggthemes)
library(ggrepel)
# time series toolkits
library(xts)
library(tsibble)
url_ <- "https://raw.githubusercontent.com/leontoddjohnson/i590/main/data/quakes/quakes.csv"
quakes <- read_delim(url_, delim = ",")
# filter only pertinent time series data, and remove duplicates
quakes_ <- quakes |>
select(time, latitude, longitude, mag) |>
distinct()
# look at the data
# View(quakes_)
# create a tsibble of daily earthquake counts
quakes_ts <- as_tsibble(quakes_, index=time) |>
index_by(date = date(time)) |>
summarise(num_quakes = sum(!is.na(mag))) |>
fill_gaps()
# an "xts" object separate from the original
quakes_xts <- xts(x = quakes_ts$num_quakes,
order.by = quakes_ts$date)
quakes_xts <- setNames(quakes_xts, "quakes")
quakes_xts %>%
rollapply(width = 30, \(x) mean(x, na.rm = TRUE), fill = FALSE) %>%
ggplot(mapping = aes(x = Index, y = quakes)) +
geom_line() +
labs(title = "Earthquakes Over Time",
subtitle = "Monthly Rolling Average") +
theme_hc()
quakes_ts |>
filter_index("2022" ~ "2023") |>
drop_na() |>
ggplot(mapping = aes(x = date, y = num_quakes)) +
geom_point(size=1, shape='O') +
geom_smooth(span=0.2, color = 'blue', se=FALSE) +
labs(title = "Earthquakes During 2022") +
theme_hc()
quakes_ts |>
filter_index("2021-01" ~ "2022-06") |>
ggplot(mapping = aes(x = date, y = num_quakes)) +
geom_line() +
geom_smooth(method = 'lm', color = 'blue', se=FALSE) +
labs(title = "Earthquakes the First Half of 2022") +
theme_hc()
quakes_ts |>
index_by(year = floor_date(date, 'halfyear')) |>
summarise(avg_quakes = mean(num_quakes, na.rm = TRUE)) |>
ggplot(mapping = aes(x = year, y = avg_quakes)) +
geom_line() +
geom_smooth(span = 0.3, color = 'blue', se=FALSE, ) +
labs(title = "Average Earthquakes Over Time",
subtitle = "(by half year)") +
scale_x_date(breaks = "1 year", labels = \(x) year(x)) +
theme_hc()
quakes_ts |>
ggplot(mapping = aes(x = date, y = num_quakes)) +
geom_line() +
labs(title = "Earthquakes Over Time") +
theme_hc()
# ... ISSUE ...
# **bonus points** to anyone who can figure it out!
# decompose(quakes_xts)
library(wikipediatrend)
hits <- wpd_get_exact(page="Time_series",
from="2008-01-01",
to="2013-01-01",
lang="en",
warn=TRUE)
# filter only pertinent time series data, and remove duplicates
quakes_ <- quakes |>
select(time, latitude, longitude, mag) |>
distinct()
# look at the data
View(quakes_)
# create a tsibble of daily earthquake counts
quakes_ts <- as_tsibble(quakes_, index=time) |>
index_by(date = date(time)) |> # index_by() similar to group_by()
summarise(num_quakes = sum(!is.na(mag))) |> # n() not being used because we assume that certain value is not present i.e. mag is not ,
fill_gaps() # fill implicit missing values (16th jan to 18th jan, 17th jan doesnt exist) - index needs to have continuity, otherwise errors might be issue.
quakes_ts
# create a tsibble of daily earthquake counts
quakes_ts <- as_tsibble(quakes_, index=time) |>
index_by(date = date(time)) |> # index_by() similar to group_by()
summarise(num_quakes = sum(!is.na(mag))) |> # n() not being used because we assume that certain value is not present i.e. mag is not ,
fill_gaps() # fill implicit missing values (16th jan to 18th jan, 17th jan doesnt exist) - index needs to have continuity, otherwise errors might be issue.
quakes_ts.head(20)
# create a tsibble of daily earthquake counts
quakes_ts <- as_tsibble(quakes_, index=time) |>
index_by(date = date(time)) |> # index_by() similar to group_by()
summarise(num_quakes = sum(!is.na(mag))) |> # n() not being used because we assume that certain value is not present i.e. mag is not ,
fill_gaps() # fill implicit missing values (16th jan to 18th jan, 17th jan doesnt exist) - index needs to have continuity, otherwise errors might be issue.
head(quakes_ts)
# an "xts" object separate from the original
quakes_xts <- xts(x = quakes_ts$num_quakes,
order.by = quakes_ts$date)
quakes_xts <- setNames(quakes_xts, "quakes")
head(quakes_xts)
quakes_ts|>
ggplot() +
geom_line(mapping = aes( x= data, y=num_quakes))
quakes_ts|>
ggplot() +
geom_line(mapping = aes( x= data, y=num_quakes))+
theme_hc()
quakes_ts|>
ggplot() +
geom_line(mapping = aes( x= date, y=num_quakes))+
theme_hc()
# ... ISSUE ...
# **bonus points** to anyone who can figure it out!
decompose(quakes_ts)
# ... ISSUE ...
# **bonus points** to anyone who can figure it out!
decompose(quakes_)
hits <- wpd_get_exact(page="Time_series",
from="2008-01-01",
to="2013-01-01",
lang="en",
warn=TRUE)
library(wikipediatrend)
hits <- wpd_get_exact(page="Time_series",
from="2008-01-01",
to="2013-01-01",
lang="en",
warn=TRUE)
install.packages("wikipediatrend")
library(wikipediatrend)
install.packages("wikipediatrend")
hits <- wpd_get_exact(page="Time_series",
from="2008-01-01",
to="2013-01-01",
lang="en",
warn=TRUE)
install.packages("wikipediatrend")
library(wikipediatrend)
hits <- wpd_get_exact(page="Time_series",
from="2008-01-01",
to="2013-01-01",
lang="en",
warn=TRUE)
library(tidyverse)
library(ggthemes)
library(ggrepel)
# time series toolkits
library(xts)
library(tsibble)
url_ <- "https://raw.githubusercontent.com/leontoddjohnson/i590/main/data/quakes/quakes.csv"
quakes <- read_delim(url_, delim = ",")
# filter only pertinent time series data, and remove duplicates
quakes_ <- quakes |>
select(time, latitude, longitude, mag) |>
distinct()
# look at the data
View(quakes_)
# create a tsibble of daily earthquake counts
quakes_ts <- as_tsibble(quakes_, index=time) |>
index_by(date = date(time)) |> # index_by() similar to group_by()
summarise(num_quakes = sum(!is.na(mag))) |> # n() not being used because we assume that certain value is not present i.e. mag is not ,
fill_gaps() # fill implicit missing values (16th jan to 18th jan, 17th jan doesnt exist) - index needs to have continuity, otherwise errors might be issue.
head(quakes_ts)
# an "xts" object separate from the original
quakes_xts <- xts(x = quakes_ts$num_quakes,
order.by = quakes_ts$date)
quakes_xts <- setNames(quakes_xts, "quakes")
head(quakes_xts)
quakes_ts|>
ggplot() +
geom_line(mapping = aes( x= date, y=num_quakes))+
theme_hc()
quakes_xts %>%
rollapply(width = 30, \(x) mean(x, na.rm = TRUE), fill = FALSE) %>%
ggplot(mapping = aes(x = Index, y = quakes)) +
geom_line() +
labs(title = "Earthquakes Over Time",
subtitle = "Monthly Rolling Average") +
theme_hc()
quakes_ts |>
filter_index("2022" ~ "2023") |>
drop_na() |>
ggplot(mapping = aes(x = date, y = num_quakes)) +
geom_point(size=1, shape='O') +
geom_smooth(span=0.2, color = 'blue', se=FALSE) +
labs(title = "Earthquakes During 2022") +
theme_hc()
quakes_ts |>
filter_index("2021-01" ~ "2022-06") |>
ggplot(mapping = aes(x = date, y = num_quakes)) +
geom_line() +
geom_smooth(method = 'lm', color = 'blue', se=FALSE) +
labs(title = "Earthquakes the First Half of 2022") +
theme_hc()
quakes_ts |>
index_by(year = floor_date(date, 'halfyear')) |>
summarise(avg_quakes = mean(num_quakes, na.rm = TRUE)) |>
ggplot(mapping = aes(x = year, y = avg_quakes)) +
geom_line() +
geom_smooth(span = 0.3, color = 'blue', se=FALSE, ) +
labs(title = "Average Earthquakes Over Time",
subtitle = "(by half year)") +
scale_x_date(breaks = "1 year", labels = \(x) year(x)) +
theme_hc()
quakes_ts |>
ggplot(mapping = aes(x = date, y = num_quakes)) +
geom_line() +
labs(title = "Earthquakes Over Time") +
theme_hc()
# ... ISSUE ...
# **bonus points** to anyone who can figure it out!
# decompose(quakes_ts)
#install.packages("wikipediatrend")
library(wikipediatrend)
hits <- wpd_get_exact(page="Time_series",
from="2008-01-01",
to="2013-01-01",
lang="en",
warn=TRUE)
#install.packages("wikipediatrend")
library(wikipediatrend)
library(tidyverse)
library(ggthemes)
library(ggrepel)
# time series toolkits
library(xts)
library(tsibble)
url_ <- "https://raw.githubusercontent.com/leontoddjohnson/i590/main/data/quakes/quakes.csv"
quakes <- read_delim(url_, delim = ",")
# filter only pertinent time series data, and remove duplicates
quakes_ <- quakes |>
select(time, latitude, longitude, mag) |>
distinct()
# look at the data
View(quakes_)
# create a tsibble of daily earthquake counts
quakes_ts <- as_tsibble(quakes_, index=time) |>
index_by(date = date(time)) |> # index_by() similar to group_by()
summarise(num_quakes = sum(!is.na(mag))) |> # n() not being used because we assume that certain value is not present i.e. mag is not ,
fill_gaps() # fill implicit missing values (16th jan to 18th jan, 17th jan doesnt exist) - index needs to have continuity, otherwise errors might be issue.
head(quakes_ts)
# an "xts" object separate from the original
quakes_xts <- xts(x = quakes_ts$num_quakes,
order.by = quakes_ts$date)
quakes_xts <- setNames(quakes_xts, "quakes")
head(quakes_xts)
quakes_ts|>
ggplot() +
geom_line(mapping = aes( x= date, y=num_quakes))+
theme_hc()
quakes_xts %>%
rollapply(width = 30, \(x) mean(x, na.rm = TRUE), fill = FALSE) %>%
ggplot(mapping = aes(x = Index, y = quakes)) +
geom_line() +
labs(title = "Earthquakes Over Time",
subtitle = "Monthly Rolling Average") +
theme_hc()
quakes_ts |>
filter_index("2022" ~ "2023") |>
drop_na() |>
ggplot(mapping = aes(x = date, y = num_quakes)) +
geom_point(size=1, shape='O') +
geom_smooth(span=0.2, color = 'blue', se=FALSE) +
labs(title = "Earthquakes During 2022") +
theme_hc()
quakes_ts |>
filter_index("2021-01" ~ "2022-06") |>
ggplot(mapping = aes(x = date, y = num_quakes)) +
geom_line() +
geom_smooth(method = 'lm', color = 'blue', se=FALSE) +
labs(title = "Earthquakes the First Half of 2022") +
theme_hc()
quakes_ts |>
index_by(year = floor_date(date, 'halfyear')) |>
summarise(avg_quakes = mean(num_quakes, na.rm = TRUE)) |>
ggplot(mapping = aes(x = year, y = avg_quakes)) +
geom_line() +
geom_smooth(span = 0.3, color = 'blue', se=FALSE, ) +
labs(title = "Average Earthquakes Over Time",
subtitle = "(by half year)") +
scale_x_date(breaks = "1 year", labels = \(x) year(x)) +
theme_hc()
quakes_ts |>
ggplot(mapping = aes(x = date, y = num_quakes)) +
geom_line() +
labs(title = "Earthquakes Over Time") +
theme_hc()
# ... ISSUE ...
# **bonus points** to anyone who can figure it out!
# decompose(quakes_ts)
#install.packages("wikipediatrend")
library(wikipediatrend)
hits <- wpd_get_exact(page="Time_series",
from="2008-01-01",
to="2013-01-01",
lang="en",
warn=TRUE)
