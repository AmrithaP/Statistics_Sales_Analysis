sample4 |> select("Category","Expected_probability_Category","Category_Special_tag")
ggplot(Category_group, aes(x = Category, y = total_count_category, fill = Category)) +
geom_bar(stat = "identity") +
labs(
title = "Total Count by Category",
x = "CAtegory",
y = "Total Count"
) +
theme_minimal()
merged_data <- merge(Superstore_data, Segment_group, by = "Segment", all.x = TRUE)
# Define a function to calculate 'Segment_Special_tag'
Segment_Special_tag <- function(total_count_segment) {
if (total_count_segment >= 3020) {
return("normal")
}else {
return("low")
}
}
# Apply the function to create 'Segment_anomaly' column
merged_data$Segment_Special_tag <- sapply(merged_data$total_count_segment, Segment_Special_tag)
# Print the resulting table
print(merged_data|> select("Segment","Expected_probability_Segment","Segment_Special_tag")|> sample_n(10) )
merged_data <- merge(Superstore_data, Region_group, by = "Region", all.x = TRUE)
# Define a function to calculate 'Segment_Special_tag'
Region_Special_tag <- function(total_count_segment) {
if (total_count_segment >= 2323) {
return("normal")
}else {
return("low")
}
}
# Apply the function to create 'Segment_anomaly' column
merged_data$Region_Special_tag <- sapply(merged_data$total_count_region, Region_Special_tag)
# Print the resulting table
print(merged_data|> select("Segment","Expected_probability_Region","Region_Special_tag")|> sample_n(10))
merged_data <- merge(Superstore_data, Region_group, by = "Region", all.x = TRUE)
# Define a function to calculate 'Segment_Special_tag'
Region_Special_tag <- function(total_count_segment) {
if (total_count_segment >= 2323) {
return("normal")
}else {
return("low")
}
}
# Apply the function to create 'Segment_anomaly' column
merged_data$Region_Special_tag <- sapply(merged_data$total_count_region, Region_Special_tag)
# Print the resulting table
print(merged_data|> select("Region","Expected_probability_Region","Region_Special_tag")|> sample_n(10))
merged_data <- merge(Superstore_data, Category_group, by = "Category", all.x = TRUE)
# Define a function to calculate 'Segment_Special_tag'
Category_Special_tag <- function(total_count_category) {
if (total_count_category >= 1848) {
return("normal")
}else {
return("low")
}
}
# Apply the function to create 'Segment_anomaly' column
merged_data$Category_Special_tag <- sapply(merged_data$total_count_category, Category_Special_tag)
# Print the resulting table
print(merged_data|> select("Category","Expected_probability_Category","Category_Special_tag")|> sample_n(10))
knitr::opts_chunk$set(echo = TRUE)
# Load tidyverse
library(tidyverse)
library(dplyr)
Superstore_data=read.csv("SampleSuperstore_final.csv")
head(Superstore_data)
# Load tidyverse
library(tidyverse)
library(dplyr)
Superstore_data=read.csv("SampleSuperstore_final.csv")
head(Superstore_data)
nrow(Superstore_data)
# 50 % of 9994
0.5 * 9994
# Population - count :
# Rows of data in the data set -
nrow(Superstore_data)
# Sample - should be as long as roughly 50% percent of your data.
# 50 % of 9994
sample_size <- 0.5 * 9994
sample_size
sample_1 <- sample(Superstore_data, size = 0.5, replace = TRUE)
sample_1
sample_1 <- sample(Superstore_data, size = 5000, replace = TRUE)
sample_1
sample_1 <- sample_frac(0.5, replace = TRUE)
sample_1 <- Superstore_data |> sample_frac(0.5, replace = TRUE)
nrow(sample_1)
sample_1[:20]
sample_1[20]
sample_1_n(20)
sample_1 |> sample_n(20)
sample_2 <- Superstore_data |> sample_frac(0.5, replace = TRUE)
nrow(sample_2)
sample_1 |> sample_n(20)
intersect(sample_1, sample_2)
sample_2 |> sample_n(20)
#intersect(sample_1, sample_2)
sample_3 <- Superstore_data |> sample_frac(0.5, replace = TRUE)
nrow(sample_3)
sample_3 |> sample_n(20)
intersect(sample_1, sample_3)
intersect(sample_1, sample_2)
nrow(intersect(sample_1, sample_2))
nrow(intersect(sample_2, sample_2))
nrow(intersect(sample_2, sample_3))
sample_3 |> sample_n(20)
sample_4 <- Superstore_data |> sample_frac(0.5, replace = TRUE)
nrow(sample_4)
sample_4 |> sample_n(20)
sample_4 |> sample_n(20)
nrow(intersect(sample_4, sample_3))
nrow(intersect(sample_1, sample_3))
nrow(intersect(sample_1, sample_4))
sample_5 <- Superstore_data |> sample_frac(0.5, replace = TRUE)
nrow(sample_5)
sample_5 |> sample_n(20)
nrow(intersect(sample_5, sample_4))
nrow(intersect(sample_1, sample_5))
sample_1 <- Superstore_data |> sample_frac(0.5, replace = TRUE) | pluck("Ship.Mode","Segment","Region", "State","Category","Sub.Category","Sales","Profit","Discount")
sample_1 <- Superstore_data |> sample_frac(0.5, replace = TRUE) | pluck("Ship.Mode","Segment","Region", "State","Category","Sub.Category","Sales","Profit","Discount")
sample_1 <- Superstore_data |> sample_frac(0.5, replace = TRUE) | select("Ship.Mode","Segment","Region", "State","Category","Sub.Category","Sales","Profit","Discount")
sample_1 <- Superstore_data |> sample_frac(0.5, replace = TRUE) |> select("Ship.Mode","Segment","Region", "State","Category","Sub.Category","Sales","Profit","Discount")
nrow(sample_1)
sample_1 |> sample_n(20)
sample_2 <- Superstore_data |> sample_frac(0.5, replace = TRUE)|> select("Ship.Mode","Segment","Region", "State","Category","Sub.Category","Sales","Profit","Discount")
nrow(sample_2)
sample_2 |> sample_n(20)
sample_3 <- Superstore_data |> sample_frac(0.5, replace = TRUE)|> select("Ship.Mode","Segment","Region", "State","Category","Sub.Category","Sales","Profit","Discount")
nrow(sample_3)
sample_3 <- Superstore_data |> sample_frac(0.5, replace = TRUE)|> select("Ship.Mode","Segment","Region", "State","Category","Sub.Category","Sales","Profit","Discount")
nrow(sample_3)
sample_3 |> sample_n(20)
sample_4 <- Superstore_data |> sample_frac(0.5, replace = TRUE) |> select("Ship.Mode","Segment","Region", "State","Category","Sub.Category","Sales","Profit","Discount")
nrow(sample_4)
sample_4 |> sample_n(20)
sample_5 <- Superstore_data |> sample_frac(0.5, replace = TRUE)|> select("Ship.Mode","Segment","Region", "State","Category","Sub.Category","Sales","Profit","Discount")
nrow(sample_5)
sample_5 |> sample_n(20)
df_sample_1 <- Superstore_data |> sample_frac(0.5, replace = TRUE) |> select("Ship.Mode","Segment","Region", "State","Category","Sub.Category","Sales","Profit","Discount")
nrow(df_sample_1)
df_sample_1 |> sample_n(20)
df_sample_2 <- Superstore_data |> sample_frac(0.5, replace = TRUE)|> select("Ship.Mode","Segment","Region", "State","Category","Sub.Category","Sales","Profit","Discount")
nrow(df_sample_2)
df_sample_2 |> sample_n(20)
#nrow(intersect(sample_1, sample_2))
df_sample_3 <- Superstore_data |> sample_frac(0.5, replace = TRUE)|> select("Ship.Mode","Segment","Region", "State","Category","Sub.Category","Sales","Profit","Discount")
nrow(df_sample_3)
nrow(intersect(df_sample_1, df_sample_2))
df_sample_3 <- Superstore_data |> sample_frac(0.5, replace = TRUE)|> select("Ship.Mode","Segment","Region", "State","Category","Sub.Category","Sales","Profit","Discount")
nrow(df_sample_3)
df_sample_3 |> sample_n(20)
df_sample_4 <- Superstore_data |> sample_frac(0.5, replace = TRUE) |> select("Ship.Mode","Segment","Region", "State","Category","Sub.Category","Sales","Profit","Discount")
nrow(df_sample_4)
df_sample_4 |> sample_n(20)
df_sample_5 <- Superstore_data |> sample_frac(0.5, replace = TRUE)|> select("Ship.Mode","Segment","Region", "State","Category","Sub.Category","Sales","Profit","Discount")
nrow(df_sample_5)
mean_df_sample_1 <- df_sample_1 |> pluck("Segment") |> mean(na.rm = TRUE)
mean_df_sample_1
mean_df_sample_1 <- df_sample_1 |> group_by(Segment) |>
summarise(total_count_segment=n(),
.groups = 'drop')
mean_df_sample_1
mean_df_sample_2 <- df_sample_2 |> group_by(Segment) |>
summarise(total_count_segment=n(),
.groups = 'drop')
mean_df_sample_2
mean_df_sample_3 <- df_sample_3 |> group_by(Segment) |>
summarise(total_count_segment=n(),
.groups = 'drop')
mean_df_sample_2
mean_df_sample_3 <- df_sample_3 |> group_by(Segment) |>
summarise(total_count_segment=n(),
.groups = 'drop')
mean_df_sample_3
mean_df_sample_4 <- df_sample_4 |> group_by(Segment) |>
summarise(total_count_segment=n(),
.groups = 'drop')
mean_df_sample_4
mean_df_sample_5 <- df_sample_5 |> group_by(Segment) |>
summarise(total_count_segment=n(),
.groups = 'drop')
mean_df_sample_5
count_df_sample_1 <- df_sample_1 |> group_by(State) |>
summarise(total_count_state=n(),
.groups = 'drop')
count_df_sample_1
count_df_sample_1 <- df_sample_1 |> group_by(State) |>
summarise(total_count_state=n(),
.groups = 'drop') |> sort()
count_df_sample_1 <- df_sample_1 |> group_by(State) |>
summarise(total_count_state=n(),
.groups = 'drop').sort()
count_df_sample_1 <- df_sample_1 |> group_by(State) |>
summarise(total_count_state=n(),
.groups = 'drop') |> arrange(desc(total_count_state))
count_df_sample_1
count_df_sample_1 <- df_sample_1 |> group_by(State) |>
summarise(total_count_state=n(),
.groups = 'drop') |>   arrange(desc(total_count_state))
head(count_df_sample_1)
tail(count_df_sample_1,10)
count_df_sample_1 <- df_sample_1 |> group_by(State) |>
summarise(total_count_state=n(),
.groups = 'drop') |>   arrange(desc(total_count_state))
head(count_df_sample_1, 10)
count_df_sample_1 <- df_sample_1 |> group_by(State) |>
summarise(total_count_state=n(),
.groups = 'drop') |>   arrange(desc(total_count_state))
head(count_df_sample_1, 10)
tail(count_df_sample_1,10)
count_df_sample_1 <- df_sample_1 |> group_by(State) |>
summarise(total_count_state=n(),
.groups = 'drop') |>   arrange(desc(total_count_state))
head(count_df_sample_1, 10)
tail(count_df_sample_1,10)
count_df_sample_2 <- df_sample_2 |> group_by(State) |>
summarise(total_count_state=n(),
.groups = 'drop') |>   arrange(desc(total_count_state))
head(count_df_sample_2, 10)
tail(count_df_sample_2,10)
knitr::opts_chunk$set(eval = FALSE)
knitr::opts_chunk$set(eval = FALSE)
# Population - count :
# Rows of data in the data set -
nrow(Superstore_data)
# Sample - should be as long as roughly 50% percent of your data.
# 50 % of 9994
sample_size <- 0.5 * 9994
sample_size
df_sample_1 <- Superstore_data |> sample_frac(0.5, replace = TRUE) |> select("Ship.Mode","Segment","Region", "State","Category","Sub.Category","Sales","Profit","Discount")
# Load tidyverse
library(tidyverse)
library(dplyr)
Superstore_data=read.csv("SampleSuperstore_final.csv")
head(Superstore_data)
knitr::opts_chunk$set(eval = FALSE)
# Population - count :
# Rows of data in the data set -
nrow(Superstore_data)
# Sample - should be as long as roughly 50% percent of your data.
# 50 % of 9994
sample_size <- 0.5 * 9994
sample_size
df_sample_1 <- Superstore_data |> sample_frac(0.5, replace = TRUE) |> select("Ship.Mode","Segment","Region", "State","Category","Sub.Category","Sales","Profit","Discount")
nrow(df_sample_1)
df_sample_1 |> sample_n(20)
df_sample_2 <- Superstore_data |> sample_frac(0.5, replace = TRUE)|> select("Ship.Mode","Segment","Region", "State","Category","Sub.Category","Sales","Profit","Discount")
nrow(df_sample_2)
df_sample_2 |> sample_n(20)
#nrow(intersect(df_sample_1, df_sample_2))
df_sample_3 <- Superstore_data |> sample_frac(0.5, replace = TRUE)|> select("Ship.Mode","Segment","Region", "State","Category","Sub.Category","Sales","Profit","Discount")
nrow(df_sample_3)
df_sample_3 |> sample_n(20)
df_sample_4 <- Superstore_data |> sample_frac(0.5, replace = TRUE) |> select("Ship.Mode","Segment","Region", "State","Category","Sub.Category","Sales","Profit","Discount")
nrow(df_sample_4)
df_sample_4 |> sample_n(20)
df_sample_5 <- Superstore_data |> sample_frac(0.5, replace = TRUE)|> select("Ship.Mode","Segment","Region", "State","Category","Sub.Category","Sales","Profit","Discount")
nrow(df_sample_5)
df_sample_5 |> sample_n(20)
count_df_sample_1 <- df_sample_1 |> group_by(Segment) |>
summarise(total_count_segment=n(),
.groups = 'drop')
count_df_sample_1
count_df_sample_2 <- df_sample_2 |> group_by(Segment) |>
summarise(total_count_segment=n(),
.groups = 'drop')
count_df_sample_2
count_df_sample_3 <- df_sample_3 |> group_by(Segment) |>
summarise(total_count_segment=n(),
.groups = 'drop')
count_df_sample_3
count_df_sample_4 <- df_sample_4 |> group_by(Segment) |>
summarise(total_count_segment=n(),
.groups = 'drop')
count_df_sample_4
count_df_sample_5 <- df_sample_5 |> group_by(Segment) |>
summarise(total_count_segment=n(),
.groups = 'drop')
count_df_sample_5
count_df_sample_1 <- df_sample_1 |> group_by(State) |>
summarise(total_count_state=n(),
.groups = 'drop') |>   arrange(desc(total_count_state))
head(count_df_sample_1, 10)
tail(count_df_sample_1,10)
count_df_sample_2 <- df_sample_2 |> group_by(State) |>
summarise(total_count_state=n(),
.groups = 'drop') |>   arrange(desc(total_count_state))
head(count_df_sample_2, 10)
tail(count_df_sample_2,10)
knitr::opts_chunk$set(echo = FALSE)
count_df_sample_1 <- df_sample_1 |> group_by(State) |>
summarise(total_count_state=n(),
.groups = 'drop') |>   arrange(desc(total_count_state))
head(count_df_sample_1, 10)
tail(count_df_sample_1,10)
count_df_sample_2 <- df_sample_2 |> group_by(State) |>
summarise(total_count_state=n(),
.groups = 'drop') |>   arrange(desc(total_count_state))
head(count_df_sample_2, 10)
tail(count_df_sample_2,10)
count_df_sample_3 <- df_sample_3 |> group_by(State) |>
summarise(total_count_state=n(),
.groups = 'drop') |>   arrange(desc(total_count_state))
head(count_df_sample_3, 10)
tail(count_df_sample_3,10)
count_df_sample_4 <- df_sample_4 |> group_by(State) |>
summarise(total_count_state=n(),
.groups = 'drop') |>   arrange(desc(total_count_state))
head(count_df_sample_4, 10)
tail(count_df_sample_4,10)
count_df_sample_5 <- df_sample_5 |> group_by(State) |>
summarise(total_count_state=n(),
.groups = 'drop') |>   arrange(desc(total_count_state))
head(count_df_sample_5, 10)
tail(count_df_sample_5,10)
count_df_sample_1 <- df_sample_1 |> group_by(Segment,State) |>
summarise(total_count_segment=n(),
.groups = 'drop')
count_df_sample_1
count_df_sample_1 <- df_sample_1 |> group_by(Segment,State) |>
summarise(total_count_segment_state=n(),
.groups = 'drop') |>
arrange(desc(total_count_segment_state))
count_df_sample_1
count_df_sample_1 <- df_sample_1 |> pluck("Sales") | mean()
count_df_sample_1 <- df_sample_1 |> pluck("Sales") | mean(na.rm=TRUE)
df_sample_1 |> pluck("Sales") | mean(na.rm=TRUE)
df_sample_1 |> pluck("Sales")
df_sample_1 |> pluck("Sales") |mean()
df_sample_1 |> pluck("Sales") |mean(Sales)
df_sample_1 |> pluck("Sales") |> mean(na.rm=TRUE)
mean_Sample_2 <- df_sample_2 |> pluck("Sales") |> mean(na.rm=TRUE)
mean_Sample_2
mean_Sample_3 <- df_sample_3 |> pluck("Sales") |> mean(na.rm=TRUE)
mean_Sample_3
mean_Sample_4 <- df_sample_4 |> pluck("Sales") |> mean(na.rm=TRUE)
mean_Sample_4
mean_Sample_5 <- df_sample_5 |> pluck("Sales") |> mean(na.rm=TRUE)
mean_Sample_5
mean_Sample_1 <- df_sample_1 |> pluck("Sales") |> max(na.rm=TRUE)
mean_Sample_1
max_Sample_1 <- df_sample_1 |> pluck("Sales") |> max(na.rm=TRUE)
max_Sample_1
max_Sample_1 <- df_sample_1 |> pluck("Sales") |> max(na.rm=TRUE)
max_Sample_1
max_Sample_2 <- df_sample_2 |> pluck("Sales") |> max(na.rm=TRUE)
max_Sample_2
max_Sample_3 <- df_sample_3 |> pluck("Sales") |> max(na.rm=TRUE)
max_Sample_3
max_Sample_4 <- df_sample_4 |> pluck("Sales") |> max(na.rm=TRUE)
max_Sample_4
max_Sample_5 <- df_sample_5 |> pluck("Sales") |> max(na.rm=TRUE)
max_Sample_5
min_Sample_1 <- df_sample_1 |> pluck("Sales") |> min(na.rm=TRUE)
min_Sample_1
min_Sample_2 <- df_sample_2 |> pluck("Sales") |> min(na.rm=TRUE)
min_Sample_2
min_Sample_3 <- df_sample_3 |> pluck("Sales") |> min(na.rm=TRUE)
min_Sample_3
min_Sample_4 <- df_sample_4 |> pluck("Sales") |> max(na.rm=TRUE)
max_Sample_4
min_Sample_4 <- df_sample_4 |> pluck("Sales") |> min(na.rm=TRUE)
min_Sample_4
min_Sample_5 <- df_sample_5 |> pluck("Sales") |> min(na.rm=TRUE)
min_Sample_5
nrow(intersect(df_sample_1, df_sample_2))
nrow(intersect(df_sample_1, df_sample_3))
nrow(intersect(df_sample_2, df_sample_3))
nrow(intersect(df_sample_3, df_sample_4))
nrow(intersect(df_sample_4, df_sample_5))
count_df_sample_1 <- df_sample_1 |> group_by(Segment,State) |>
summarise(total_count_segment_state=n(),
.groups = 'drop') |>
arrange(desc(Segment),.by_group= TRUE)
count_df_sample_1
count_df_sample_1 <- df_sample_1 |> group_by(Segment,State) |>
summarise(total_count_segment_state=n(),
.groups = 'drop') |>
arrange(desc(State,Segment),.by_group= TRUE)
count_df_sample_1 <- df_sample_1 |> group_by(Segment,State) |>
summarise(total_count_segment_state=n(),
.groups = 'drop') |>
arrange(desc(State),.by_group= TRUE)
count_df_sample_1
count_df_sample_1 <- df_sample_1 |> group_by(State,Segment) |>
summarise(total_count_segment_state=n(),
.groups = 'drop') |>
arrange(desc(State),.by_group= TRUE)
count_df_sample_1
count_df_sample_1 <- df_sample_1 |> group_by(State,Segment) |>
summarise(total_count_segment_state=n(),
.groups = 'drop') |>
arrange(State,.by_group= TRUE)
count_df_sample_1
count_df_sample_1 <- df_sample_1 |> group_by(State,Segment) |>
summarise(total_count_segment_state=n(),
.groups = 'drop') |>
arrange(total_count_segment_state,.by_group= TRUE)
count_df_sample_1
count_df_sample_1 <- df_sample_1 |> group_by(State,Segment) |>
summarise(total_count_segment_state=n(),
.groups = 'drop') |>
arrange(total_count_segment_state,.by_group= TRUE)
count_df_sample_1["State"=="New York"]
count_df_sample_1 <- df_sample_1 |> group_by(State,Segment) |>
summarise(total_count_segment_state=n(),
.groups = 'drop') |>
arrange(total_count_segment_state,.by_group= TRUE)
count_df_sample_1["State"="New York"]
count_df_sample_1 <- df_sample_1 |> group_by(State,Segment) |>
summarise(total_count_segment_state=n(),
.groups = 'drop') |>
arrange(desc(total_count_segment_state),.by_group= TRUE)
count_df_sample_1
mean_Sample_1 <- df_sample_1 |> pluck("Profit") |> mean(na.rm=TRUE)
mean_Sample_1
mean_Sample_2 <- df_sample_2 |> pluck("Profit") |> mean(na.rm=TRUE)
mean_Sample_2
mean_Sample_3 <- df_sample_3 |> pluck("Profit") |> mean(na.rm=TRUE)
mean_Sample_3
mean_Sample_4 <- df_sample_4 |> pluck("Profit") |> mean(na.rm=TRUE)
mean_Sample_4
mean_Sample_5 <- df_sample_5 |> pluck("Profit") |> mean(na.rm=TRUE)
mean_Sample_5
max_Sample_1 <- df_sample_1 |> pluck("Profit") |> max(na.rm=TRUE)
max_Sample_1
max_Sample_2 <- df_sample_2 |> pluck("Profit") |> max(na.rm=TRUE)
max_Sample_2
max_Sample_3 <- df_sample_3 |> pluck("Profit") |> max(na.rm=TRUE)
max_Sample_3
max_Sample_4 <- df_sample_4 |> pluck("Profit") |> max(na.rm=TRUE)
max_Sample_4
max_Sample_5 <- df_sample_5 |> pluck("Profit") |> max(na.rm=TRUE)
max_Sample_5
min_Sample_1 <- df_sample_1 |> pluck("Profit") |> min(na.rm=TRUE)
min_Sample_1
min_Sample_2 <- df_sample_2 |> pluck("Profit") |> min(na.rm=TRUE)
min_Sample_2
min_Sample_3 <- df_sample_3 |> pluck("Profit") |> min(na.rm=TRUE)
min_Sample_3
min_Sample_4 <- df_sample_4 |> pluck("Profit") |> min(na.rm=TRUE)
min_Sample_4
min_Sample_5 <- df_sample_5 |> pluck("Sales") |> min(na.rm=TRUE)
min_Sample_5
count_df_sample_1 <- df_sample_1 |> group_by(Region,Discount) |>
summarise(total_count_region_sales=sum(),
.groups = 'drop') |>
arrange(desc(total_count_region_sales),.by_group= TRUE)
count_df_sample_1
count_df_sample_1 <- df_sample_1 |> group_by(Region,Sales) |>
summarise(total_count_region_sales=sum(),
.groups = 'drop') |>
arrange(desc(total_count_region_sales),.by_group= TRUE)
count_df_sample_1
count_df_sample_1 <- df_sample_1 |> group_by(Region) |>
summarise(total_count_region_sales=sum(Sales),
.groups = 'drop') |>
arrange(desc(total_count_region_sales),.by_group= TRUE)
count_df_sample_1
count_df_sample_1 <- df_sample_1 |> group_by(Region) |>
summarise(total_count_region_sales=mean(Sales),
.groups = 'drop') |>
arrange(desc(total_count_region_sales),.by_group= TRUE)
count_df_sample_1
count_df_sample_1 <- df_sample_1 |> group_by(Region) |>
summarise(total_count_region_sales=max(Sales),
.groups = 'drop') |>
arrange(desc(total_count_region_sales),.by_group= TRUE)
count_df_sample_1
count_df_sample_1 <- df_sample_1 |> group_by(Region) |>
summarise(total_max_region_sales=max(Sales),
.groups = 'drop') |>
arrange(desc(total_max_region_sales),.by_group= TRUE)
count_df_sample_1
count_df_sample_2 <- df_sample_2 |> group_by(Region) |>
summarise(total_max_region_sales=max(Sales),
.groups = 'drop') |>
arrange(desc(total_max_region_sales),.by_group= TRUE)
count_df_sample_2
count_df_sample_3 <- df_sample_3 |> group_by(Segment) |>
summarise(total_max_region_sales=max(Sales),
.groups = 'drop') |>
arrange(desc(total_max_region_sales),.by_group= TRUE)
count_df_sample_3
count_df_sample_3 <- df_sample_3 |> group_by(Region) |>
summarise(total_max_region_sales=max(Sales),
.groups = 'drop') |>
arrange(desc(total_max_region_sales),.by_group= TRUE)
count_df_sample_3
count_df_sample_4 <- df_sample_4 |> group_by(Region) |>
summarise(total_max_region_sales=max(Sales),
.groups = 'drop') |>
arrange(desc(total_max_region_sales),.by_group= TRUE)
count_df_sample_4
count_df_sample_3 <- df_sample_3 |> group_by(Region) |>
summarise(total_max_region_sales=max(Sales),
.groups = 'drop') |>
arrange(desc(total_max_region_sales),.by_group= TRUE)
count_df_sample_3
count_df_sample_5 <- df_sample_5 |> group_by(Region) |>
summarise(total_max_region_sales=max(Sales),
.groups = 'drop') |>
arrange(desc(total_max_region_sales),.by_group= TRUE)
count_df_sample_5
knitr::opts_chunk$set(eval = FALSE)
# Sample - should be as long as roughly 50% percent of your data.
# 50 % of 9994
sample_size <- 0.5 * 9994
sample_size
knit_with_parameters("E:/IUPUI/SEM 1/Intro to Stats/week 4/Data Dive â€” Sampling and Drawing Conclusions_Amritha Prakash.Rmd")
